{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TubesCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEmzmtNqxvrv"
      },
      "source": [
        "# Convolutional Neural Network dengan PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-P0mPxZLVG8"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Silakan upload cnn_grc.zip ke files.\n",
        "\n",
        "Alternatif lain, bisa juga dataset di upload ke storage lain lalu nanti didownload dengan cmommand lin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODpEClPHJ0rO"
      },
      "source": [
        "import torch as pt # turunan\n",
        "import numpy as np # numerical python\n",
        "import pandas as pd # bermain dataset\n",
        "import copy # untuk copy2 an"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQmBdfp2BjCD",
        "outputId": "3a236fad-4991-4a44-a107-1d7c563ba43a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avhBIhiszpri"
      },
      "source": [
        "!cp \"/content/drive/Shareddrives/Deep Learning/cnn.zip\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMUpTxJuLUqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3bee0b-2a13-432e-b801-caf2745c543a"
      },
      "source": [
        "# extract file zip\n",
        "# tanda seru artinya ini bukan perintah Python, melainkan perintah command prompt ubuntu\n",
        "! unzip cnn.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cnn.zip\n",
            "replace cnn/BECAK0150.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eiG6id4LRsd"
      },
      "source": [
        "### Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TnOKvJhxyuL"
      },
      "source": [
        "import torch as pt # library utama pytorch\n",
        "import numpy as np # numerical python\n",
        "import pandas as pd # bermain dataset\n",
        "import copy # untuk copy2 an\n",
        "\n",
        "# libray lain pytorch untuk membangun arsitektur\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "\n",
        "# library dar pytorch untuk pengelolaan dataset khususnya data citra\n",
        "from torchvision import transforms, datasets, models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsK_3FRxWWhy"
      },
      "source": [
        "### Preprocessing\n",
        "Pada bagian ini kita akan memperbaiki data agar enak dibaca CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39bNbUzGLPHN"
      },
      "source": [
        "train_dir = \"cnn/train/\"\n",
        "test_dir = \"cnn/test/\"\n",
        "\n",
        "# fungsi transform bertugas untuk \"mengedit\" data yang masuk\n",
        "# macam-macam perintah yang bisa dilakukan bisa cek di sini: https://pytorch.org/docs/stable/torchvision/transforms.html\n",
        "\n",
        "train_transform = transforms.Compose([ # proses transform dilakukan secara berurutan\n",
        "    transforms.RandomHorizontalFlip(p=0.2),\n",
        "    transforms.Resize(500),\n",
        "    transforms.CenterCrop(224), # 1. di crop ukuran 150x150 di tengah citra\n",
        "    transforms.ToTensor(), # 2. di ubah ke tensor\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(500),          \n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# load dataset dengan format folder yang sesuai lalu aplikasikan transformasi ke data yang dibaca\n",
        "# hasil dari proses ini adalah sebuah list berelemen tuple (tensor_citra, label) disebut dengan objek datasets\n",
        "train_img = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "test_img = datasets.ImageFolder(test_dir, transform=test_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQBKK-lInyHo"
      },
      "source": [
        "# bagian ini intinya mengubah objek datasets di atas ke format yang lebih baik :)\n",
        "# insyaAllah akan dijelaskan di pertemuan selanjutnya\n",
        "trainloaders = pt.utils.data.DataLoader(train_img, batch_size=19, shuffle=True)\n",
        "testloaders = pt.utils.data.DataLoader(test_img, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nzq8eMRWSgQ"
      },
      "source": [
        "# Informasi dari dataset kita\n",
        "print(\"train_img type   :\",type(train_img)) # objek datasets\n",
        "\n",
        "print(\"train_img length :\",len(train_img)) # 515 data train\n",
        "print(\"test_img length :\",len(test_img)) # 66 data test\n",
        "\n",
        "print(\"train_img classes:\",train_img.classes) # nama kelas\n",
        "print(\"train_img classes:\",train_img.class_to_idx) # nama kelas\n",
        "\n",
        "print(\"train_img[0] type:\",type(train_img[0])) # tuple (A, B)\n",
        "print(\"train_img[0][0]  :\",train_img[0][0].size()) # tensor citra\n",
        "print(\"train_img[0][1]  :\",train_img[0][1]) # label\n",
        "\n",
        "# variabel banyak data\n",
        "len_train = len(train_img)\n",
        "len_test = len(test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UssQHHz7j-_J"
      },
      "source": [
        "### Buat Arsitektur"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2tjZ6Npj-YF"
      },
      "source": [
        "pt.manual_seed(123)\n",
        "class Net(nn.Module):\n",
        "   \n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=0)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        # ukuran sisi = ((ukuran - kernel_size + 2 * padding) / stride + 1)\n",
        "        # hasil flatten = sisi * sisi * feature_maps\n",
        "        self.fc1 = nn.Linear(42632, 3) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        # forward propagation\n",
        "        x = self.conv1(x) # convolusi\n",
        "        x = F.relu(x) # fungsi aktivasi\n",
        "        x = self.pool(x) # pooling\n",
        "        x = x.reshape(x.shape[0], -1) # flattening\n",
        "        x = F.relu(self.fc1(x)) # layer biasa\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jF42PcVUWdFB"
      },
      "source": [
        "modelkita = Net().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h186-pXbz7PL"
      },
      "source": [
        "modelkita"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rchiu6a-V4y7"
      },
      "source": [
        "modelkita = models.resnet18(pretrained=True)\n",
        "\n",
        "#freezing\n",
        "for param in modelkita.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# hapus layer terakhir\n",
        "modelkita.fc = nn.Linear(512, 3)\n",
        "\n",
        "modelkita = modelkita.cuda()\n",
        "print(modelkita)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLKs_GA8lpga"
      },
      "source": [
        "optimizer = pt.optim.Adagrad(modelkita.parameters(), lr=0.01) # algoritma training\n",
        "criterion = nn.CrossEntropyLoss() # rumus error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJF4Ohf7nGUD"
      },
      "source": [
        "### Mulai Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaxfFPyWmcz2"
      },
      "source": [
        "modelkita.train()\n",
        "for i in range(7): # 10 epoch\n",
        "\n",
        "    rata2error = 0 # untuk menghitung error (\"seberapa salah\")\n",
        "    jumlahbenar = 0 # untuk menghitung akurasi (\"seberapa benar\")\n",
        "\n",
        "    for image, label in trainloaders: # iterasi semua data\n",
        "        \n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "        # forward\n",
        "        Y = modelkita( image )\n",
        "        E = criterion( Y, label )\n",
        "        rata2error += E\n",
        "\n",
        "        prediksi = pt.max(Y, dim=1).indices\n",
        "        for i in range(len(prediksi)):\n",
        "            if prediksi[i]==label[i]:\n",
        "                jumlahbenar+=1\n",
        "        \n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        E.backward()       \n",
        "\n",
        "        # update\n",
        "        optimizer.step() \n",
        "\n",
        "    print(rata2error/len_train, jumlahbenar/len_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srVykYJAyySw"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LRi8G0My0nO"
      },
      "source": [
        "modelkita.eval()\n",
        "\n",
        "with pt.no_grad():\n",
        "    rata2error = 0 # untuk menghitung error (\"seberapa salah\")\n",
        "    jumlahbenar = 0 # untuk menghitung akurasi (\"seberapa benar\")\n",
        "\n",
        "    for image, label in testloaders: # iterasi semua data\n",
        "        \n",
        "        image = image.cuda()\n",
        "        label = label.cuda()\n",
        "\n",
        "        # forward\n",
        "        Y = modelkita( image )\n",
        "        E = criterion( Y, label )\n",
        "        rata2error += E\n",
        "\n",
        "        prediksi = pt.max(Y, dim=1).indices\n",
        "        for i in range(len(prediksi)):\n",
        "            if prediksi[i]==label[i]:\n",
        "                jumlahbenar+=1\n",
        "\n",
        "    print(rata2error/len_test, jumlahbenar/len_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMtnaVo0xysL"
      },
      "source": [
        "### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE1sCdIfx1Jg"
      },
      "source": [
        "pt.save(modelkita, \"modelkita_v4.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOU_wKU1xuTm"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e5-sOWuyK1R"
      },
      "source": [
        "# load model\n",
        "modelbaru = pt.load(\"modelkita_v4.pth\", map_location=pt.device(\"cpu\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGH3MEYmnsJJ"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "modelbaru.eval()\n",
        "\n",
        "# load single image\n",
        "single_img = Image.open(\"/content/cnn/BECAK0150.jpg\")\n",
        "\n",
        "# transform\n",
        "single_img_transformed = test_transform(single_img)\n",
        "\n",
        "Y = modelbaru( single_img_transformed.unsqueeze(0) )\n",
        "\n",
        "prediksi = pt.max(Y, dim=1).indices\n",
        "print(prediksi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MLXQSyd1BJo"
      },
      "source": [
        "prediksi.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AXwUJZ-EXMU"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "modelbaru.eval()\n",
        "\n",
        "# load single image\n",
        "single_img = Image.open(\"/content/mobil6.jpg\").convert(\"RGB\")\n",
        "\n",
        "# transform\n",
        "single_img_transformed = test_transform(single_img)\n",
        "\n",
        "Y = modelbaru( single_img_transformed.unsqueeze(0) )\n",
        "\n",
        "prediksi = pt.max(Y, dim=1).indices\n",
        "print(prediksi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRcwgIExHGwM"
      },
      "source": [
        "prediksi.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHQMLmsSHI8I"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "modelbaru.eval()\n",
        "\n",
        "# load single image\n",
        "single_img = Image.open(\"/content/motor1.jpg\").convert('RGB')\n",
        "\n",
        "# transform\n",
        "single_img_transformed = test_transform(single_img)\n",
        "\n",
        "Y = modelbaru( single_img_transformed.unsqueeze(0) )\n",
        "\n",
        "prediksi = pt.max(Y, dim=1).indices\n",
        "print(prediksi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhrGhK3RHHNQ"
      },
      "source": [
        "prediksi.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euMz6h_3HVss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}